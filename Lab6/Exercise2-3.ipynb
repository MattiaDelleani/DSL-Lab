{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 - Loading Data an split test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "dataset = fetch_openml(\"mnist_784\")\n",
    "X = dataset[\"data\"]\n",
    "y = dataset[\"target\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(X,y, test_size = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 - Build a DTClassifier and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873\n",
      "[0.92198582 0.94780447 0.83783784 0.85784314 0.87054027 0.82197802\n",
      " 0.9000999  0.90445269 0.81766704 0.81874356] \n",
      " [0.9164149  0.95652174 0.84221526 0.83095916 0.88132095 0.83111111\n",
      " 0.90826613 0.90866729 0.78393051 0.84038055] \n",
      " [0.91919192 0.95214315 0.84002084 0.84418717 0.87589744 0.82651934\n",
      " 0.90416458 0.90655509 0.80044346 0.82942097] \n",
      " [ 993 1196  957 1053  969  900  992 1073  921  946]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(precision,\"\\n\", recall,\"\\n\", f1, \"\\n\",support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "row_idx = random.sample(range(0,X.shape[0]+1),5)\n",
    "col_idx = random.sample(range(0,X.shape[1]+1),3 )\n",
    "r = X[:, col_idx]\n",
    "r[row_idx, :]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3 - 2.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestClassifier():\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_estimators, max_features):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "    # train the trees of this random forest using subsets of X (and y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.random_tree = []\n",
    "        self.cols_idx = []\n",
    "        self.rows_idx = []\n",
    "        self.importance = {}\n",
    "        for i in range(self.n_estimators):\n",
    "            row_idx = random.sample(range(0,X.shape[0]),int(X.shape[0]*0.625))\n",
    "            col_idx = random.sample(range(0,X.shape[1]),self.max_features)\n",
    "            \n",
    "            self.cols_idx.append(col_idx)\n",
    "            self.rows_idx.append(row_idx)\n",
    "            \n",
    "            yb = y[row_idx]\n",
    "            Xb = X[row_idx,:]\n",
    "            Xb = Xb[:, col_idx]\n",
    "            clf = DecisionTreeClassifier(max_depth= 10)\n",
    "            clf.fit(Xb, yb)\n",
    "            self.random_tree.append(clf)\n",
    "            #importance[n_estimators] = classifier.feature_importances_\n",
    "            \n",
    "    \n",
    "    # predict the label for each point in X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for i in range(self.n_estimators):\n",
    "            y_pred = self.random_tree[i].predict(X[:, self.cols_idx[i]])\n",
    "            result.append(y_pred)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def importance(self):\n",
    "        \n",
    "        return self.importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyRandomForestClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-f4eb67fff6d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimportance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MyRandomForestClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "result = {}\n",
    "importance = {}\n",
    "for n_estimators in range(10,100,10):\n",
    "    classifier = MyRandomForestClassifier(n_estimators, int(math.sqrt(X.shape[1])))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    result[n_estimators] =  classifier.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict ={}\n",
    "\n",
    "for  k, v in (result.items()):\n",
    "    #report = classification_report(y_test, y_p)\n",
    "    #print(report)\n",
    "    accuracy_dict[k] = []\n",
    "    for value in v:\n",
    "        \n",
    "        accuracy_dict[k].append(accuracy_score(y_test, value))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.5146</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.5972</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6378</td>\n",
       "      <td>0.5805</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6463</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.6008</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.5895</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.6197</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.6455</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.7038</td>\n",
       "      <td>0.5479</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.6059</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.6123</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.7077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8   \\\n",
       "10  0.6517  0.6598  0.6189  0.5773  0.6323  0.6791  0.6694  0.6727  0.5146   \n",
       "20  0.4983  0.6506  0.6016  0.5719  0.6079  0.5565  0.6396  0.6353  0.5972   \n",
       "30  0.6659  0.5997  0.6304  0.6366  0.5707  0.6438  0.4882  0.6929  0.6543   \n",
       "40  0.5728  0.6397  0.5883  0.6541  0.7227  0.6496  0.6808  0.6624  0.6378   \n",
       "50  0.6249  0.5782  0.6406  0.6402  0.6495  0.6463  0.6107  0.6171  0.6412   \n",
       "60  0.6008  0.6547  0.5895  0.6273  0.5990  0.6197  0.6068  0.6724  0.5899   \n",
       "70  0.6100  0.6068  0.6148  0.6591  0.7143  0.6773  0.6808  0.6596  0.6598   \n",
       "80  0.5250  0.6625  0.6462  0.6455  0.6603  0.6251  0.5670  0.6464  0.7038   \n",
       "90  0.6059  0.6396  0.6310  0.7233  0.6485  0.6123  0.6185  0.6820  0.6631   \n",
       "\n",
       "        9   ...      80      81      82     83      84      85     86      87  \\\n",
       "10  0.6381  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "20  0.6521  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "30  0.5573  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "40  0.5805  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "50  0.6795  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "60  0.6493  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "70  0.7002  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "80  0.5479  ...     NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN   \n",
       "90  0.6259  ...  0.6855  0.6764  0.6597  0.539  0.6016  0.6475  0.595  0.7006   \n",
       "\n",
       "        88      89  \n",
       "10     NaN     NaN  \n",
       "20     NaN     NaN  \n",
       "30     NaN     NaN  \n",
       "40     NaN     NaN  \n",
       "50     NaN     NaN  \n",
       "60     NaN     NaN  \n",
       "70     NaN     NaN  \n",
       "80     NaN     NaN  \n",
       "90  0.5776  0.7077  \n",
       "\n",
       "[9 rows x 90 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame.from_dict(accuracy_dict, orient= 'index')\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    0.661250\n",
       "20    0.611265\n",
       "30    0.630340\n",
       "40    0.636208\n",
       "50    0.648864\n",
       "60    0.635437\n",
       "70    0.631179\n",
       "80    0.626121\n",
       "90    0.627954\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_mean = df_result.mean(axis = 1)\n",
    "row_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy:0.6612500000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max accuracy:{row_mean.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance- How do I compute it if every MyRandom is composed by different classifier, they return me the same value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame.from_dict(importance, orient = \"index\")\n",
    "type(impoertances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "779    0.0\n",
       "780    0.0\n",
       "781    0.0\n",
       "782    0.0\n",
       "783    0.0\n",
       "Name: 10, Length: 784, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.loc[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "10  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "20  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "30  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "40  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "50  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "60  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "70  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "80  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "90  0.000036  0.000037  0.000073  0.000054  0.000168  0.000054  0.000073   \n",
       "\n",
       "         7         8         9    ...       488       489       490       491  \\\n",
       "10  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "20  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "30  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "40  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "50  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "60  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "70  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "80  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "90  0.000169  0.000105  0.000126  ...  0.000102  0.000208  0.000107  0.000037   \n",
       "\n",
       "         492       493       494       495       496       497  \n",
       "10  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "20  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "30  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "40  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "50  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "60  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "70  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "80  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "90  0.000034  0.000339  0.000063  0.000168  0.000198  0.000073  \n",
       "\n",
       "[9 rows x 498 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_importance = {}\n",
    "for row in importances.index:\n",
    "    positive_importance[row] = []\n",
    "    for col in importances.columns:\n",
    "        if(importances.loc[row, col] >0):\n",
    "            positive_importance[row].append(importances.loc[row, col])\n",
    "\n",
    "            \n",
    "df_pos_importance = pd.DataFrame.from_dict(positive_importance, orient = \"index\")\n",
    "df_pos_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos_importance.iloc[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.5 - Random forest classifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "#timeit.timeit(lambda: apriori(df, 0.01), number=1)\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_result = {}\n",
    "for n_est in range(10,100,10):\n",
    "    classifier = RandomForestClassifier(n_estimators = n_est, max_depth= 10, max_features= \"sqrt\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    rnd_result[n_est] =  classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier.predict() --> The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.9410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.9423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.9420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "10  0.9235\n",
       "20  0.9350\n",
       "30  0.9393\n",
       "40  0.9450\n",
       "50  0.9410\n",
       "60  0.9423\n",
       "70  0.9433\n",
       "80  0.9420\n",
       "90  0.9450"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_accuracy_dict ={}\n",
    "\n",
    "for  k, v in (rnd_result.items()):\n",
    "    #report = classification_report(y_test, y_p)\n",
    "    #print(report)\n",
    "    rnd_accuracy_dict[k] =(accuracy_score(y_test, v))\n",
    "        \n",
    "rnd_df_result = pd.DataFrame.from_dict(rnd_accuracy_dict, orient= 'index')\n",
    "rnd_df_result\n",
    "#print(rnd_accuracy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we increase the number of features the accuracy grow. max_features = \"auto\" --> total features; =\"sqrt\" -->sqrt(tot); if we set 10 whic is less than sqrt(tot) the accurcy decrease but the efficency increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
